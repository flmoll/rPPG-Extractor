{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb780ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import butter\n",
    "import pickle\n",
    "import glob\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/workspaces/src/rPPG-Toolbox\")\n",
    "\n",
    "from evaluation.gt_visualize import GTVisualizer\n",
    "from neural_methods.model.HRClassifierQuantile import HRClassifierQuantile\n",
    "\n",
    "global_output_folder = \"graphics/\"\n",
    "save_extension = \"svg\"\n",
    "\n",
    "f_res = 0.005\n",
    "sampling_rate = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c58ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x_values = np.arange(0, N)\n",
    "sinusoid = np.sin(x_values / 50)\n",
    "random_shuffled = np.random.permutation(sinusoid)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "axs[0].plot(x_values, sinusoid, label='Original Sinusoid')\n",
    "axs[0].set_title('Original Sinusoid')\n",
    "\n",
    "axs[1].plot(x_values, random_shuffled, label='Randomly Shuffled Sinusoid')\n",
    "axs[1].set_title('Randomly Shuffled Sinusoid')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(global_output_folder, f\"sinusoid_comparison.{save_extension}\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45169380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_kernel_showcase(gaussian_1_mean, gaussian_1_std, gaussian_2_mean, gaussian_2_std, gt_value_x):\n",
    "\n",
    "    gaussian_kernel_x = np.arange(-3 * gaussian_1_std + gaussian_1_mean, 3 * gaussian_1_std + gaussian_1_mean, f_res)\n",
    "    gaussian_kernel = -(1/(gaussian_1_std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((gaussian_kernel_x - gaussian_1_mean) / gaussian_1_std) ** 2)\n",
    "    gaussian_2_kernel = -(1/(gaussian_2_std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((gaussian_kernel_x - gaussian_2_mean) / gaussian_2_std) ** 2)\n",
    "\n",
    "    plt.plot(gaussian_kernel_x, gaussian_kernel, label='High uncertainty')\n",
    "    plt.plot(gaussian_kernel_x, gaussian_2_kernel, label='Low uncertainty')\n",
    "\n",
    "    if gt_value_x is not None:\n",
    "        plt.axvline(x=gt_value_x, color='r', linestyle='--', label='Ground Truth Frequency')\n",
    "        #plt.annotate(f'Data Likelihood: {data_likelihood:.3f}', xy=(gt_value_x, 1), xytext=(gaussian_mean + gaussian_std/2, 0.95),fontsize=12, color='red')\n",
    "    plt.xlabel('Network Output')\n",
    "    plt.ylabel('Data Likelihood')\n",
    "    plt.title('DNN output as Gaussian Distribution')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d8e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_1_mean = 1.1\n",
    "gaussian_1_std = 0.1\n",
    "gaussian_2_mean = 1.1\n",
    "gaussian_2_std = 0.05\n",
    "gt_value_x = 1.0\n",
    "\n",
    "plot_gaussian_kernel_showcase(gaussian_1_mean, gaussian_1_std, gaussian_2_mean, gaussian_2_std, gt_value_x)\n",
    "plt.savefig(os.path.join(global_output_folder, f\"gaussian_kernel_showcase_bad_prediction.{save_extension}\"))\n",
    "plt.close()\n",
    "\n",
    "plot_gaussian_kernel_showcase(1.04, gaussian_1_std, 1.04, gaussian_2_std, gt_value_x)\n",
    "plt.savefig(os.path.join(global_output_folder, f\"gaussian_kernel_showcase_good_prediction.{save_extension}\"))\n",
    "plt.close()\n",
    "\n",
    "plot_gaussian_kernel_showcase(1.04, gaussian_1_std, 1.04, gaussian_2_std, None)\n",
    "plt.savefig(os.path.join(global_output_folder, f\"gaussian_kernel_showcase.{save_extension}\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee218e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "# Simulate labels and predictions for visualization\n",
    "labels = np.linspace(-2, 2, 400)\n",
    "# Wide interval\n",
    "preds_lower_wide = np.full_like(labels, -1.5)\n",
    "preds_upper_wide = np.full_like(labels, 1.5)\n",
    "# Small interval\n",
    "preds_lower_small = np.full_like(labels, -0.5)\n",
    "preds_upper_small = np.full_like(labels, 0.5)\n",
    "\n",
    "def quantile_loss(labels, preds_lower, preds_upper, alpha):\n",
    "    loss_lower = np.maximum(alpha * (labels - preds_lower), (alpha - 1) * (labels - preds_lower))\n",
    "    loss_upper = np.maximum(alpha * (preds_upper - labels), (alpha - 1) * (preds_upper - labels))\n",
    "    return loss_lower + loss_upper\n",
    "\n",
    "loss_wide = quantile_loss(labels, preds_lower_wide, preds_upper_wide, alpha)\n",
    "loss_small = quantile_loss(labels, preds_lower_small, preds_upper_small, alpha)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(labels, loss_wide, label='Wide Interval')\n",
    "plt.plot(labels, loss_small, label='Small Interval')\n",
    "plt.xlabel('Network Output')\n",
    "plt.ylabel('Quantile Loss')\n",
    "plt.title('Quantile Loss for Wide and Small Prediction Intervals')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(global_output_folder, f\"quantile_loss_intervals.{save_extension}\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f76989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle_0_flat(data, data_to_load=\"predictions\", normalize=True):\n",
    "\n",
    "    if isinstance(data, str):\n",
    "        with open(data, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "    data_dict = data[data_to_load]\n",
    "    data_list = []\n",
    "\n",
    "    for key in data_dict.keys():\n",
    "        for i in range(len(data_dict[key])):\n",
    "            curr_data = np.array(data_dict[key][i].cpu().numpy())\n",
    "\n",
    "            if normalize:\n",
    "                curr_data = (curr_data - np.mean(curr_data)) / np.std(curr_data)\n",
    "\n",
    "            data_list.append(curr_data)\n",
    "\n",
    "    return np.array(data_list).reshape(len(data_dict.keys()), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca8c0ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (32, 1, 800), Predictions shape: (32, 1, 800)\n",
      "Ground Truth Frequency: 0.94 Hz\n",
      "First Harmonic Frequency: 1.88 Hz\n",
      "Lower Interval: [0.84, 1.04] Hz\n",
      "Upper Interval: [1.77, 1.98] Hz\n"
     ]
    }
   ],
   "source": [
    "results_file = \"/workspaces/src/rPPG-Toolbox/runs/DeepStab/test/VitalVideos_and_UBFC_SizeW72_SizeH72_ClipLength160_DataTypeDiffNormalized_Standardized_DataAugNone_LabelTypeDiffNormalized_Crop_faceTrue_BackendY5F_Large_boxTrue_Large_size1.5_Dyamic_DetTrue_det_len30_Median_face_boxFalse_DNone_amp10.0/saved_test_outputs/VitalLens_Physnet_best_VitalVideos_and_UBFC_outputs.pickle\"\n",
    "\n",
    "sampling_rate = 30.0  # Assuming a sampling rate of 30 Hz\n",
    "index_to_use = 0  # Index of the data to visualize\n",
    "\n",
    "labels = read_from_pickle_0_flat(results_file, data_to_load=\"labels\", normalize=True)\n",
    "predictions = read_from_pickle_0_flat(results_file, data_to_load=\"predictions\", normalize=True)\n",
    "print(f\"Labels shape: {labels.shape}, Predictions shape: {predictions.shape}\")\n",
    "labels = labels[index_to_use, 0, :]\n",
    "predictions = predictions[index_to_use, 0, :]\n",
    "\n",
    "fft_label = np.fft.fft(labels)\n",
    "freq_label = np.fft.fftfreq(len(labels), d=1/sampling_rate)\n",
    "fft_prediction = np.fft.fft(predictions)\n",
    "freq_prediction = np.fft.fftfreq(len(predictions), d=1/sampling_rate)\n",
    "\n",
    "freq_label = freq_label[:len(freq_label)//2]\n",
    "fft_label = fft_label[:len(fft_label)//2]\n",
    "freq_prediction = freq_prediction[:len(freq_prediction)//2]\n",
    "fft_prediction = fft_prediction[:len(fft_prediction)//2]\n",
    "\n",
    "# Get the first and second harmonics of the ground truth HR in Hz\n",
    "first_harmonic_freq = freq_label[np.argmax(np.abs(fft_label))]\n",
    "second_harmonic_freq = 2 * first_harmonic_freq\n",
    "deviation = 6 / 60  # 6 beats/min converted to Hz (1 Hz = 60 beats/min)\n",
    "\n",
    "lower_interval_start = first_harmonic_freq - deviation\n",
    "lower_interval_end = first_harmonic_freq + deviation\n",
    "upper_interval_start = second_harmonic_freq - deviation\n",
    "upper_interval_end = second_harmonic_freq + deviation\n",
    "\n",
    "print(f\"Ground Truth Frequency: {first_harmonic_freq:.2f} Hz\")\n",
    "print(f\"First Harmonic Frequency: {second_harmonic_freq:.2f} Hz\")\n",
    "print(f\"Lower Interval: [{lower_interval_start:.2f}, {lower_interval_end:.2f}] Hz\")\n",
    "print(f\"Upper Interval: [{upper_interval_start:.2f}, {upper_interval_end:.2f}] Hz\")\n",
    "\n",
    "\n",
    "#plt.plot(freq_label, np.abs(fft_label), label='FFT of Label')\n",
    "plt.plot(freq_prediction, np.abs(fft_prediction), label='FFT of Prediction')\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(global_output_folder, f\"fft_prediction.{save_extension}\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65eb2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "[b, a] = butter(1, [0.6 / sampling_rate * 2, 3.3 / sampling_rate * 2], btype='bandpass')\n",
    "predictions_filt = scipy.signal.filtfilt(b, a, np.double(predictions))\n",
    "labels_filt = scipy.signal.filtfilt(b, a, np.double(labels))\n",
    "\n",
    "fft_label_filt = np.fft.fft(labels_filt)\n",
    "freq_label_filt = np.fft.fftfreq(len(labels_filt), d=1/sampling_rate)\n",
    "fft_prediction_filt = np.fft.fft(predictions_filt)\n",
    "freq_prediction_filt = np.fft.fftfreq(len(predictions_filt), d=1/sampling_rate)\n",
    "\n",
    "freq_label_filt = freq_label_filt[:len(freq_label_filt)//2]\n",
    "fft_label_filt = fft_label_filt[:len(fft_label_filt)//2]\n",
    "freq_prediction_filt = freq_prediction_filt[:len(freq_prediction_filt)//2]\n",
    "fft_prediction_filt = fft_prediction_filt[:len(fft_prediction_filt)//2]\n",
    "\n",
    "#plt.plot(freq_label_filt, np.abs(fft_label_filt), label='FFT of Filtered Label')\n",
    "plt.plot(freq_prediction_filt, np.abs(fft_prediction_filt), label='FFT of Filtered Prediction')\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(global_output_folder, f\"fft_prediction_filt.{save_extension}\"))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e66dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr = np.correlate(labels_filt, labels_filt, mode='full')\n",
    "autocorr = autocorr[autocorr.size // 2:]  # Keep only non-negative lags\n",
    "frequency = np.arange(0, len(autocorr)) / sampling_rate\n",
    "\n",
    "plt.plot(frequency, autocorr)\n",
    "plt.xlim(0, 5)\n",
    "plt.title('Autocorrelation of PPG Signal')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.savefig(os.path.join(global_output_folder, f\"autocorrelation_ppg_signal.{save_extension}\"))\n",
    "plt.close()\n",
    "\n",
    "time = np.arange(0, len(labels_filt)) / sampling_rate\n",
    "plt.plot(time, labels_filt)\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Filtered PPG Signal')\n",
    "plt.savefig(os.path.join(global_output_folder, f\"filtered_ppg_signal.{save_extension}\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b2e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#plt.plot(freq_label_filt, np.abs(fft_label_filt), label='FFT of Filtered Label')\n",
    "plt.plot(freq_prediction_filt, np.abs(fft_prediction_filt), label='FFT of Filtered Prediction')\n",
    "plt.axvline(x=lower_interval_start, color='r', linestyle='--', label='Ground Truth Frequency')\n",
    "plt.axvline(x=lower_interval_end, color='r', linestyle='--')\n",
    "plt.axvline(x=upper_interval_start, color='g', linestyle='--', label='First Harmonic')\n",
    "plt.axvline(x=upper_interval_end, color='g', linestyle='--')\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(global_output_folder, f\"fft_prediction_filt_with_snr_intervals.{save_extension}\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dcc60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data_vital_videos(data_path):\n",
    "    \"\"\"Returns data directories under the path(For Preprocessed Vital Videos dataset).\"\"\"\n",
    "    data_dirs = glob.glob(data_path + os.sep + \"*.mp4\")\n",
    "    if not data_dirs:\n",
    "        raise ValueError(\"data paths empty!\")\n",
    "    dirs = list()\n",
    "    for data_dir in data_dirs:\n",
    "        folder_name = os.path.basename(data_dir)\n",
    "        subject = folder_name.split(\"_\")[0]\n",
    "        index = int(folder_name.split(\"_\")[1].split(\".\")[0])\n",
    "        gt_file_name = os.path.join(data_path, f\"{subject}.json\")\n",
    "        gt_visualizer = GTVisualizer(gt_file_name, folder_name)\n",
    "\n",
    "        location = gt_visualizer.get_location()['location']\n",
    "\n",
    "        # Check if the corresponding JSON file exists\n",
    "        json_file = os.path.join(data_path, f\"{subject}.json\")\n",
    "        if not os.path.exists(json_file):\n",
    "            raise ValueError(f\"JSON file {json_file} does not exist for subject {subject}. Skipping this directory.\")\n",
    "\n",
    "        # Append the directory information to the list\n",
    "        dirs.append({\"index\": index, \"path\": data_dir, \"subject\": subject, \"location\": location})\n",
    "    \n",
    "    dirs = sorted(dirs, key=lambda x: (x['location'] + x['path']))\n",
    "\n",
    "    for i in range(len(dirs)):\n",
    "        dirs[i]['index'] = i\n",
    "\n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4374a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_chart(data_list, title, filename):\n",
    "    print(data_list)\n",
    "    labels = list(set(data_list))\n",
    "    counts = [data_list.count(label) for label in labels]\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 20})\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.savefig(os.path.join(global_output_folder, filename))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f553df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(data_list, title, filename):\n",
    "    data_list = [int(age) for age in data_list if age.isdigit()]  # Filter out non-numeric ages\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data_list, bins=10, edgecolor='black')\n",
    "    plt.title(title, fontsize=25)\n",
    "    plt.xlabel('Age', fontsize=20)\n",
    "    plt.ylabel('Frequency', fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.savefig(os.path.join(global_output_folder, filename))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b019ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_dataset_stats(data_dirs, dataset_name=\"Test\"):\n",
    "    \"\"\"Evaluate dataset statistics.\"\"\"\n",
    "    num_samples = len(data_dirs)\n",
    "    print(f\"Number of samples in the dataset: {num_samples}\")\n",
    "\n",
    "    genders_list = []\n",
    "    ages_list = []\n",
    "    fitzpatricks_list = []\n",
    "    locations_list = []\n",
    "\n",
    "    # Example: Print first 5 entries\n",
    "    for curr_dir in data_dirs:\n",
    "        curr_video_path = curr_dir['path']\n",
    "        curr_json_path = os.path.join(os.path.dirname(curr_video_path), f\"{curr_dir['subject']}.json\")\n",
    "\n",
    "        gt_visualizer = GTVisualizer(curr_json_path, curr_video_path)\n",
    "        location = gt_visualizer.get_location()['location']\n",
    "        fitzpatrick = gt_visualizer.get_fitzpatrick()\n",
    "        age = gt_visualizer.get_age()\n",
    "        gender = gt_visualizer.get_gender()\n",
    "\n",
    "        genders_list.append(gender.strip())\n",
    "        ages_list.append(age.strip())\n",
    "        fitzpatricks_list.append(fitzpatrick.strip())\n",
    "        locations_list.append(location.strip())\n",
    "\n",
    "\n",
    "    plot_pie_chart(genders_list, 'Gender Distribution', f'{dataset_name}_gender_distribution_pie.{save_extension}')\n",
    "    plot_pie_chart(fitzpatricks_list, 'Fitzpatrick Skin Type Distribution', f'{dataset_name}_fitzpatrick_distribution_pie.{save_extension}')\n",
    "    plot_pie_chart(locations_list, 'Location Distribution', f'{dataset_name}_location_distribution_pie.{save_extension}')\n",
    "    plot_histogram(ages_list, 'Age Distribution', f'{dataset_name}_age_distribution_pie.{save_extension}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40057537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 32\n",
      "['F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M']\n",
      "['4', '4', '2', '2', '2', '2', '3', '3', '5', '5', '5', '5', '2', '2', '4', '4', '2', '2', '4', '4', '3', '3', '2', '2', '3', '3', '1', '1', '3', '3', '2', '2']\n",
      "['KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KU', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL', 'KUL']\n",
      "Number of samples in the dataset: 141\n",
      "['M', 'M', 'F', 'F', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'M', 'M']\n",
      "['2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '2', '2', '2', '2', '2', '2', '6', '6', '4', '4', '4', '4', '3', '3', '3', '6', '6', '2', '2', '3', '3', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '2', '2', '6', '6', '4', '4', '3', '3', '3', '3', '2', '2', '3', '3', '2', '2', '6', '6', '4', '4', '2', '2', '3', '3', '2', '2', '5', '5', '3', '3', '4', '4', '1', '1', '4', '4', '6', '6', '4', '4', '2', '2', '5', '5', '5', '5', '4', '4', '5', '5', '2', '2', '4', '4', '3', '3', '4', '4', '6', '6', '5', '5', '5', '5', '3', '3', '6', '6', '2', '2', '5', '5', '3', '3', '4', '4', '2', '2', '6', '6', '6', '6', '2', '2', '3', '3', '3', '3', '5', '5', '2', '2', '5', '5', '2', '2', '1', '1', '5', '5']\n",
      "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL', 'KLL']\n",
      "Number of samples in the dataset: 29\n",
      "['M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'M', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F']\n",
      "['1', '1', '2', '2', '4', '4', '1', '1', '5', '5', '5', '5', '2', '4', '4', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n",
      "['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC', 'WZC']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"/mnt/data/vitalVideos\"\n",
    "train_split = range(0, 141)  # Example split, adjust as needed\n",
    "valid_split = range(173, 202)  # Example split, adjust as needed\n",
    "test_split = range(141, 173)  # Example split, adjust as needed\n",
    "\n",
    "location_names = [\"B\", \"KL\", \"KLL\", \"KU\", \"KUL\", \"T\", \"WZC\"]\n",
    "location_splits = {\n",
    "    \"B\": range(0, 14),\n",
    "    \"KL\": range(14, 31),\n",
    "    \"KLL\": range(31, 141),\n",
    "    \"KU\": range(141, 155),\n",
    "    \"KUL\": range(155, 173),\n",
    "    \"T\": range(173, 188),\n",
    "    \"WZC\": range(188, 202)\n",
    "}\n",
    "\n",
    "data_dirs = get_raw_data_vital_videos(dataset_path)\n",
    "data_dirs_train = [d for d in data_dirs if d['index'] in train_split]\n",
    "data_dirs_valid = [d for d in data_dirs if d['index'] in valid_split]\n",
    "data_dirs_test = [d for d in data_dirs if d['index'] in test_split]\n",
    "\n",
    "evaluate_dataset_stats(data_dirs_test, dataset_name=\"VitalVideos_Test\")\n",
    "evaluate_dataset_stats(data_dirs_train, dataset_name=\"VitalVideos_Train\")\n",
    "evaluate_dataset_stats(data_dirs_valid, dataset_name=\"VitalVideos_Valid\")\n",
    "\n",
    "plt.pie([len(locations_split) for locations_split in location_splits.values()],\n",
    "        labels=location_names,\n",
    "        #autopct='%1.1f%%',\n",
    "        startangle=140,\n",
    "        textprops={'fontsize': 20})\n",
    "plt.savefig(os.path.join(global_output_folder, f\"location_distribution_pie.{save_extension}\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
